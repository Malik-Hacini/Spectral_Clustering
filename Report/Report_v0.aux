\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\bibstyle{alpha-en}
\HyPL@Entry{0<</S/D>>}
\pgfsyspdfmark {pgfid1}{4736286}{50644704}
\providecommand \oddpage@label [2]{}
\babel@aux{nil}{}
\HyPL@Entry{1<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{4}{section.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison between $k$-means clustering and spectral clustering on a toy dataset}}{4}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:fig1}{{1}{4}{Comparison between $k$-means clustering and spectral clustering on a toy dataset}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}An overview of LAAS-CNRS}{5}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Foundation}{5}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces LAAS-CNRS Facility in Toulouse}}{6}{figure.caption.4}\protected@file@percent }
\newlabel{fig:laas}{{2}{6}{LAAS-CNRS Facility in Toulouse}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Lab organization and philosophy}{6}{subsection.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces LAAS' 6 research departments.}}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:laasdepartments}{{3}{6}{LAAS' 6 research departments}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}SARA}{6}{subsection.2.3}\protected@file@percent }
\citation{tutorial}
\citation{tutorial}
\@writefile{toc}{\contentsline {section}{\numberline {3}Internship's details }{7}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}The theory of Spectral Clustering}{7}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Technical explanation}{7}{subsection.4.1}\protected@file@percent }
\newlabel{sec-theory}{{4.1}{7}{Technical explanation}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Similarity graphs}{8}{subsubsection.4.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces $4$-nearest neighboirs similarity graph of a toy dataset;}}{8}{figure.caption.6}\protected@file@percent }
\newlabel{fig:sg_example}{{4}{8}{$4$-nearest neighboirs similarity graph of a toy dataset;}{figure.caption.6}{}}
\citation{tutorial}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}Graph laplacians}{9}{subsubsection.4.1.2}\protected@file@percent }
\newlabel{con_theo}{{4.1.2}{9}{Graph laplacians}{subsubsection.4.1.2}{}}
\citation{GSC}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Spectral clustering of a toy dataset with an undirected similarity graph with $2$ disconnected components.}}{10}{figure.caption.7}\protected@file@percent }
\newlabel{fig:c_example}{{5}{10}{Spectral clustering of a toy dataset with an undirected similarity graph with $2$ disconnected components}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {paragraph}{The importance of directionality}{10}{section*.8}\protected@file@percent }
\citation{tutorial}
\@writefile{toc}{\contentsline {paragraph}{The case of disconnected clusters}{11}{section*.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Connected similarity graph of a toy dataset. The color of the points represent the ground truth. }}{11}{figure.caption.10}\protected@file@percent }
\newlabel{fig:connected_example}{{6}{11}{Connected similarity graph of a toy dataset. The color of the points represent the ground truth}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Perturbation theory approach}{11}{section*.11}\protected@file@percent }
\citation{scikit}
\citation{github}
\@writefile{toc}{\contentsline {paragraph}{The eigengap heuristic}{12}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Python implementation of SC}{12}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The dataset builder.}}{12}{figure.caption.13}\protected@file@percent }
\newlabel{fig:dataset_builder}{{7}{12}{The dataset builder}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Spectral Clustering Experiments}{13}{section.6}\protected@file@percent }
\newlabel{sec-exp}{{6}{13}{Spectral Clustering Experiments}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Basic Experiments}{13}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Circles and Moons}{13}{subsubsection.6.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Comparison between $k$-means and spectral clustering on toy datasets}}{13}{figure.caption.14}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces First eigenvalues of laplacians for the clustering of the circles dataset.   Left to right : $L$, $L_{sym}$, $L_{rw}$}}{14}{figure.caption.15}\protected@file@percent }
\newlabel{fig:fige1circles}{{9}{14}{First eigenvalues of laplacians for the clustering of the circles dataset. \\ Left to right : $L$, $L_{sym}$, $L_{rw}$}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}Gaussian Mixtures}{14}{subsubsection.6.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Multivariate Normal Distribution}{14}{section*.16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Level sets of a bivariate normal distribution centered at the origin. The probability of a sample landing in the blue ellipse is $0.66$.}}{15}{figure.caption.17}\protected@file@percent }
\newlabel{fig:binorm}{{10}{15}{Level sets of a bivariate normal distribution centered at the origin. The probability of a sample landing in the blue ellipse is $0.66$}{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces $200$ samples from a mixture of two 2-dimensional gaussians.}}{15}{figure.caption.18}\protected@file@percent }
\newlabel{fig:2gm}{{11}{15}{$200$ samples from a mixture of two 2-dimensional gaussians}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Visualization of spectral clustering and it's $k$-nn graph on a gaussian mixture.   Settings : $L_{rw}$, $k=6$, $\sigma =\frac  {1}{3}$ (for gaussian kernel).}}{16}{figure.caption.19}\protected@file@percent }
\newlabel{unsuc}{{\caption@xref {unsuc}{ on input line 619}}{16}{Multivariate Normal Distribution}{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The performance of the clustering is increased with $k=8$}}{16}{figure.caption.20}\protected@file@percent }
\newlabel{fig:fig7g3}{{13}{16}{The performance of the clustering is increased with $k=8$}{figure.caption.20}{}}
\citation{GSC}
\citation{tutorial}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces First eigenvalues of laplacians for the graph of \ref {unsuc}.}}{17}{figure.caption.21}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Generalized Spectral Clustering}{17}{section.7}\protected@file@percent }
\newlabel{sec-gsc}{{7}{17}{Generalized Spectral Clustering}{section.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}GSC Experiments}{18}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Extensive study of the eigengap for SC and GSC}{18}{subsection.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.1}Method}{18}{subsubsection.8.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.2}Results}{18}{subsubsection.8.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Geometry of clusters.}{18}{section*.22}\protected@file@percent }
\newlabel{fig:base_circles}{{\caption@xref {fig:base_circles}{ on input line 681}}{19}{Geometry of clusters}{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces $k$ = 4, $L_{G_{rw}}$. A great eigengap is observed.}}{19}{figure.caption.23}\protected@file@percent }
\newlabel{fig:uneven_blobs}{{\caption@xref {fig:uneven_blobs}{ on input line 688}}{19}{Geometry of clusters}{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces $k$ = 4, $L_{G_{rw}}$. An eigengap of the same quality is observed.}}{19}{figure.caption.24}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{$N$-symmetry}{19}{section*.25}\protected@file@percent }
\newlabel{fig:mid_asym_blobs_rw}{{\caption@xref {fig:mid_asym_blobs_rw}{ on input line 702}}{20}{$N$-symmetry}{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces $k$ = 4, $L_{rw}$. There is $4$ times more points in the yellow cluster, the eigengap is worse.}}{20}{figure.caption.26}\protected@file@percent }
\newlabel{fig:4x_asym_blobs_rw}{{\caption@xref {fig:4x_asym_blobs_rw}{ on input line 709}}{20}{$N$-symmetry}{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces $k$ = 4, $L_{rw}$. There is $5$ times more points in the yellow cluster, the eigengap is practically unusable.}}{20}{figure.caption.27}\protected@file@percent }
\newlabel{fig:mid_asym_blobs_g_rw}{{\caption@xref {fig:mid_asym_blobs_g_rw}{ on input line 717}}{20}{$N$-symmetry}{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces $k$ = 4, $L_{G_{rw}}$. Even with the data being heavily unbalanced, the eigengap is clear.}}{20}{figure.caption.28}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Total number of points}{21}{section*.29}\protected@file@percent }
\newlabel{fig:circ_100_sym}{{\caption@xref {fig:circ_100_sym}{ on input line 727}}{21}{Total number of points}{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces $N=100$,$k$ = 4, $L_{G_{rw}}$. Points generated from a mixture of $2$ gaussians.}}{21}{figure.caption.30}\protected@file@percent }
\newlabel{fig:circ_500_sym}{{\caption@xref {fig:circ_500_sym}{ on input line 733}}{21}{Total number of points}{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces $N=500$, $k$ = 4, $L_{G_{rw}}$. The eigengap is significantly better than with $100$ points. }}{21}{figure.caption.31}\protected@file@percent }
\citation{UCI}
\citation{GSC}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Real datasets}{22}{subsection.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.1}Normalized Mutual Information (NMI)}{22}{subsubsection.8.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Method and results}{22}{subsection.8.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Clustering performance (NMI) on UCI datasets with optimal parameters in brackets.}}{23}{table.caption.32}\protected@file@percent }
\newlabel{tab_NMI_one}{{1}{23}{Clustering performance (NMI) on UCI datasets with optimal parameters in brackets}{table.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Unsupervised SC and GSC}{23}{appendix.A}\protected@file@percent }
\newlabel{app-unsupervised}{{A}{23}{Unsupervised SC and GSC}{appendix.A}{}}
\bibcite{tutorial}{1}
\bibcite{UCI}{2}
\bibcite{GSC}{3}
\bibcite{github}{4}
\bibcite{scikit}{5}
\gdef \@abspage@last{25}
